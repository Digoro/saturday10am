# 4. 텐서플로 다중 레이어 뉴럴 네트워크(Mnist-CNN 예제)

# CNN(Convlolutional Neural Network)
----------

**앞의 단일 계층 레이어와 비교하여 CNN은 여러개의 레이어를 차곡차곡 쌓아 다중 레이어를 구성한 것이다.**

CNN은 최근 이미지 인식 분야에서 놀라운 성능을 내고 있다.


- CNN은 딥러닝의 한 케이스이다.
- CNN의 대표적인 특징은 거의 항상 입력을 이미지로 받는 것이다.
- 이로 인해 뉴럴 네트워크를 효율적으로 구성할 수 있고 파라미터의 수를 대폭 줄일 수 있다.





## MNIST 손글씨 CNN 구성
----------
    from tensorflow.examples.tutorials.mnist import input_data
    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
    
    import tensorflow as tf
    
    x = tf.placeholder("float", shape=[None, 784])
    y_ = tf.placeholder("float", shape=[None, 10])

이전에 싱글 레이어 MNIST모델에서 작성한 것과 같이 MNIST 데이터셋을 import 받아주고 x와 y_ 플레이스 홀더를 정의하여 준다.


- x의 경우 입력받는 이미지 데이터로 28 x 28 크기의 이미지이므로 784개의 데이터를 이미지의 개수(None으로 표현)만큼 받는다.
- y_의 경우 데이터의 레이블 숫자로 손글씨의 경우 숫자 0 ~ 9를 표현하는 레이블 행렬을 이미지 개수만큼 정의하여 준다.




## 데이터셋 이미지 크기로 Reshape
----------
![](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520327628102_+2018-03-06++6.13.32.png)


다음과 같이 입력받은 데이터(x)를 기존 이미지 크기로 재구성하여 준다.


    > x_image = tf.reshape(x, [-1,28,28,1])
  

위의 Reshape 함수를 이용하여 입력 데이터를 4D 텐서로 변경하였다.


- 두 번째와 세 번째 차원은 이미지의 넓이와 높이를 의미한다.
- 네 번째 파라미터(차원)는 이미지의 컬러 채널을 의미한다.(**mnist 데이터셋은 흑백 이미지이므로 1로 지정**하였다.)
- 컬러 이미지의 경우 **RGB의 3가지 채널**로 구성된다.





## 필터(Filter) & 특성 맵(Charateristic map)
----------

Convolution Neural Network의 주요 목적은 **테두리(Edge), 선(line), 색깔 등 이미지의 시각적 특징이나 성질**을 **감지**하는 것이다. 이 것은 이전에 언급했던 입력 레이어와 연결된 히든 레이어에 의해 처리된다.


- CNN은 입력 데이터가 첫번째 히든 레이어의 뉴런에 모두 연결(Fully Connected)되어 있지 않다.
- 이미지의 픽셀 정보를 저장하고 있는 **입력 뉴런의 작은 일부 영역이 하나의 히든 레이어 뉴런과 연결**된다.


![5x5 뉴런과 연결된 히든 뉴런 예시](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520328722628_+2018-03-06++6.31.51.png)

- 정확하게 말하면 이 예에서는 히든 레이어의 각 뉴런은 입력 레이어의 5 x 5 영역(즉 25개의 뉴런)과 연결된다.
- 28 x 28의 이미지 전체를 훑고 지나가는 **5 x 5 크기의 윈도우**라고 생각할 수 있다.
- 한 픽셀씩 이동하며 훑고 지나갈 경우 전체영역을 훑는데 23번의 이동이 가능하기 때문에 **24 x 24 크기의 히든레이어 뉴런을 만든다.**
- 1픽셀씩 움직이기 때문에 윈도우가 밀려도 기존에 있던 뉴런들과 겹치는 것이 생길 수 있다.
- 물론 Convolution Layer에서 1픽셀 이상 씩 움직일 수 있다. **움직임의 크기를 정하는 파라미터를 스트라이드(stride)라고 한다.**

****
- **좀 더 좋은 결과를 내기 위해서는 이미지 밖으로 윈도우가 넘어갈 수 있도록 0으로 테두리를 채울 수 있다.** 
- 이 것을 패딩이라고 한다. 0으로 채우기 때문에 제로 패딩이라고도 한다.
## 
- 히든 레이어의 뉴런을 연결하기 위해서는 앞의 공식을 따라 5 x 5 가중치 행렬 W와 바이어스 b가 필요하다.
- CNN의 핵심 특징은 가중치 행렬 W와 바이어스 b를 **히든 레이어의 모든 뉴런이 공유**한다는 것이다.
- 즉, **히든 레이어의 모든 뉴런(여기서는 24 x 24)이 같은 W와 b를 사용한다.**
- 가중치 행렬 W를 공유함으로써 14000(5 x 5 x 24 x 24)만큼 필요했던 파라미터가 단 25(5 x 5)개로 줄어든다.


- 위에서 설명한 것과 같이 **공유하여 사용하는 가중치 행렬 W와 바이어스 b를 CNN에서는 커널(Kernel) 혹은 필터(Filter)라고 칭한다.**


![CNN의 커널 구성](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520397577831_+2018-03-07++1.39.15.png)

- **하나의 커널은 한가지 특징만을 감지한다.**
- 그러므로 **감지하고 싶은 각 특징별로 커널을 사용하는 것이 좋다.**
- 그렇기 때문에 CNN은 여러개의 커널로 구성된다.


- 이 예에서 첫 번째 히든레이어는 32개의 커널을 사용하여 구성하였다.
- 각 커널은 5 x 5 가중치 행렬 W와 하나의 바이어스 b로 정의되고 이 히든레이어의 뉴런들 모두에 공통적으로 사용된다.

 
 

## 히든 레이어의 가중치 행렬 W와 바이어스 b 함수 정의
----------
     def weight_variable(shape):
      initial = tf.truncated_normal(shape, stddev=0.1)
      return tf.Variable(initial)
    
    def bias_variable(shape):
      initial = tf.constant(0.1, shape=shape)
      return tf.Variable(initial)

**weight_variable()**

- tf.truncated_normal() 함수를 이용하여 정규분포 형식의 난수를 생성하여준다.
- 셍성한 난수를 변수로 만들어 가중치 행렬을 초기화하여 준다.

**bias_variable()**

- tf.constant() 함수를 이용하여 작은 상수값을 생성한 후에 bias 값을 초기화하였다.







## 풀링 레이어(Pooling Layer)
----------

위에서 언급한 Convolution Layer 뒤에는 Pooling Layer가 따라오는게 일반적이다. Pooling Layer는 Convolution Layer의 출력 값을 단순하게 압축해주는 역할을 한다.


![2 x 2 Pooling](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520398687981_+2018-03-07++1.58.00.png)



  
- 정보를 압축하기 위한 풀링 방법에는 여러가지가 있는데 그 중 **맥스 풀링(max-pooling) 방식**을 사용해본다.
- 맥스 풀링 방식은 위의 예제로 설명하면 **2 x 2 영역에서 가장 큰 값만을 선택하여 정보를 압축**한다.
- 앞에서 진행한 것처럼 Convolution Layer는 여러개의 커널로 이루어져 있으므로 **각각의 커널에 따로 맥스 풀링을 적용한다.**


![28 x 28 입력 이미지에서 각각의 커널 32개로 24 x 24크기로 Convolution 하였고 각 커널에 대해서 2 x 2 맥스 풀링](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520398958931_+2018-03-07++2.02.28.png)



- 24 x 24 Convolution 의 결과를 각각의 커널에 대해서 **2 x 2 맥스 풀링을 해주게 되면 12 x 12 크기의 데이터가 커널의 숫자 32개 만큼 생기게 된다.**
- Convolution Layer와 달리 데이터가 슬라이딩 윈도우에 의해 생성되는 것이 아니라 **타일처럼 나뉘어 각각 겹치는 것 없이 생성되게 된다.**

**맥스 풀링은 어떤 특징이 이미지의 여러 곳에 나타난다면 특징의 정확한 위치보다 다른 특징들과의 상대적 위치가 더 중요하다는 것을 나타낸다.**


| 위의 설명에서는 28 x 28 사이즈의 이미지가 Convolution Layer를 거치면 24 x 24사이즈로 변환된다고 설명하였지만 진행할 예제에서는 사실 Convolution Layer를 거칠 때 Padding 옵션을 ‘SAME’으로 주기 때문에 28 x 28 사이즈가 유지되도록 상하좌우에 크기 2만큼의 패딩이 각각 들어가게 됩니다. 그러므로 Convolution Layer를 지나도 사이즈는 28 x 28 사이즈로 유지되고 그후 맥스 풀링 Layer를 지나게 되면 14 x 14 사이즈로 변환되게 됩니다. |









# 모델 구현
----------

 [텐서플로우 웹사이트](https://www.tensorflow.org/get_started/mnist/pros)의 Deep MNIST for experts 예제를 기초로 모델을 작성하였다.
 
 
 

## Convolution Layer & Pooling Layer 파라미터 정의
----------

 
 Convolution Layer와 Pooling Layer를 구성하기 위해서는 여러개의 파라미터를 정해야 한다.
  

    def conv2d(x, W):
      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
    
    def max_pool_2x2(x):
      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

**Convolution Layer 파라미터**

- 각 차원 방향(4차원까지) Stride(윈도우를 이동하는 크기)는 1로 지정하였다.
- 패딩은 ‘SAME’ 옵션을 사용하여 Convolution Layer 계층을 거쳐도 크기가 그대로 유지되도록 패딩을 넣어주었다.


**Pooling Layer 파라미터**

- 풀링 레이어는 맥스 풀링 방식을 사용하였고, 2 x 2 크기의 맥스 풀링을 적용하였다.
- 쉽게 생각하자면 데이터의 ‘가로’와 ‘세로’에 대해서 풀링을 해야하기 때문에 [1, 2, 2 ,1] 2차원(가로), 3차원(세로)의 크기를 2로 지정하여 주었다.
- 윈도우를 미는 Stride는 풀링의 경우 Convolution과 다르게 겹치면 안되기 때문에 풀링 사이즈와 동일하게 [1, 2, 2, 1]로 지정하여 주었다. 
- 패딩은 동일하게 ‘SAME’ 옵션을 주었다.






## 첫 번째 Convolution Layer & Pooling Layer 정의
----------


    > W_conv1 = weight_variable([5, 5, 1, 32])
    > b_conv1 = bias_variable([32])

**가중치 행렬 W 텐서 정의**

- 이 예제에서는 윈도우 크기가 5 x 5인 32개의 필터가 존재한다.([5, 5, 1, 32])
- 처음 2개의 행렬은 윈도우의 사이즈를 의미하며 세 번째는 컬러 채널 수를 의미하는 데 흑백이므로 1이다.
- 마지막 차원은 얼마나 많은 특징을 뽑아낼 것인지를 의미하는 필터의 수로 32개의 필터를 정의하였다.

**가중치 행렬에 대한 바이어스 b 텐서 정의**

- 가중치 행렬에 대한 각각의 바이어스 b를 정의하기 위해 32 사이즈로 정의하여준다.



## Relu 활성화 함수
- Relu 활성화 함수는 최근 히든 레이어에서 사용하는 기본 활성화 함수가 되었다.
![Relu 활성화 함수](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520405959687_+2018-03-07++3.58.17.png)

- Relu 활성화 함수는 간단하게 max(0, z)의 모양을 가지며 0 이하의 음수에서는 0을 리턴하고 그 외에는 z를 return하게 된다.




    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
    h_pool1 = max_pool_2x2(h_conv1)
- 입력받은 이미지 **x_image에 대하여 합성곱(Convolution)을 적용**하고 **합성곱의 결과를 2D 텐서인 W_Conv에 저장한다.** 이 값에 **바이어스를 더하여 최종적으로 Relu 활성화 함수를 적용**하여 출력 값을 얻는다.
- 얻어진 출력 값을 이용하여 2 x 2 Max Pooling Layer에 넣어 풀링한다.





## 두 번째 Convolution Layer & Pooling Layer 정의
----------

심층 신경망을 구성할 때에는 여러 겹의 레이어를 쌓아 구성할 수 있다.

두 번째 레이어를 구현해보도록 한다.


    W_conv2 = weight_variable([5, 5, 32, 64])
    b_conv2 = bias_variable([64])
    
    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
    h_pool2 = max_pool_2x2(h_conv2)

위와 같은 방식을 이용하여 두 번째 레이어를 작성하였다.


- weight_variables()의 채널 파라미터로 이전 레이어의 출력 수인 32를 넘겨주어야 한다.
- 32개의 필터에서 64개의 필터를 갖도록 필터를 늘려주었다.



- 28 x 28의 원본 이미지가 첫 번째 레이어의 합성곱과 **2 x 2 풀링 레이어를 거쳐** 14 x 14 크기가 되었는데,  두 번째 레이어의 합성곱 층과 2 x 2 풀링 레이어를 거치면 **최종적으로 7 x 7 크기의 데이터가 출력**된다.







## 전결합층(Fully Connected Layer)
----------

위의 두 레이어를 거친 7 x 7 크기의 데이터를 이용하여 단일 레이어 뉴럴 네트워크에서 했던 것과 같이 소프트맥스 활성화 함수에 주입하기 위하여 전결합층(Fully-Connected-Layer)에 연결한다.


    W_fc1 = weight_variable([7 * 7 * 64, 1024])
    b_fc1 = bias_variable([1024])


- 가중치 행렬 W의 Fully Connected 값은 첫 번째 차원에 7 * 7 사이즈이 데이터가 64개의 필터수만큼 있으니 곱해서 파라미터로 넣어준다.
- 두 번째 파라미터는 이미지를 처리하기 위해서 사용하는 뉴런의 개수로 1024개의 뉴런을 사용한다고 정의한다.


- 이미지를 처리하는 뉴런의 개수가 1024개이므로  각각의 뉴런의 바이어스 값을 정의하기 위해 1024로 정의해주었다.






## 소프트맥스 활성화 함수 적용을 위한 텐서 직렬화
----------

이전 장에서 **소프트맥스 활성화 함수는 이미지를 직렬화해서 벡터 형태로 입력**을 해야하는 것을 확인하였다.
이를 위해 가중치 행렬 **W_fc1과 일차원 벡터를 곱하고 바이어스 b_fc1을 더한 후 Relu 활성화 함수를 적용**한다.


    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
    
    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)


- 소프트맥스 활성화 함수를 적용하기 위해 텐서를 1차원으로 직렬화하기 위하여 tf.reshape 함수를 이용하여 전체 데이터를 1차원으로 변환하여준다.
- [tf.reshape](https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/api_docs/python/array_ops.html)함수에 대한 정보는 링크에서 확인할 수 있다.


 


## 드롭아웃(dropout)
----------

드롭아웃이란 **노드를 삭제하여 입력과 출력 연결을 제거함으로써** 뉴럴 네트워크에서 필요한 **파라미터 수를 줄이는 기법**이다.


- 어떤 뉴런을 제거하고 어떤 뉴런을 유지할지는 랜덤으로 결정된다.
- 뉴런 제거나 유지 확률도 텐서플로에 위임하게 된다.


간단하게 말하면 **드롭아웃은 모델이 데이터에** **오버 피팅되는 것을 막아준다.** 히든 레이어에 많은 수의 뉴런을 사용하면 매우 상세한 모델이 만들어 지는데, 이런 경우 임의의 노이즈가 모델에 포함될 수 있다. 이를 오버피팅이라고 하고 입력 데이터의 차원에 비해 더 많은 파라미터를 가진 모델에서 자주 일어나게 된다. 오버피팅은 모델 정확성의 성능을 떨어뜨리기 때문에 피해야 한다.


    keep_prob = tf.placeholder("float")
    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)


- 위에서 진행한 예제에서는 소프트맥스 활성화 함수에 적용하기 이전에 tf.nn.dropout 함수를 사용하여 드롭아웃을 적용한다.
- 뉴런이 드롭아웃되지 않을 확률을 저장하기 위하여 keep_prop이라는 플레이스홀더를 만들어준다.







## 소프트맥스 활성화 함수 적용
----------

마지막으로 모델에 소프트맥스 레이어를 추가한다. 소프트맥스 함수는 입력 이미지가 각 클래스(0 ~ 9 사이의 숫자)에 속할 확률을 리턴한다. 0~9 까지의 전체확률을 합치면 1이 된다.

    W_fc2 = weight_variable([1024, 10])
    b_fc2 = bias_variable([10])
    
    y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)


- tf.matmul() 함수를 이용하여 매트릭스의 곱을 구한다.







# 모델 훈련 및 평가
----------

모델이 얼마나 잘 작동하는지 확인하기 위하여 이전 싱글 레이어 뉴럴 네트워크를 평가할 때는 그래디언트 최적화 알고리즘을 사용하였지만 이번 예제에서는 ADAM 최적화 알고리즘을 사용하였다.


    cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
    
    sess = tf.Session()
    
    sess.run(tf.global_variables_initializer())
    for i in range(20000):
      batch = mnist.train.next_batch(50)
      if i%100 == 0:
         train_accuracy = sess.run( accuracy, feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})
         print("step %d, training accuracy %g"%(i, train_accuracy))
      sess.run(train_step,feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})
    
    print("test accuracy %g"% sess.run(accuracy, feed_dict={ x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))


- 크로스 엔트로피에 대한 설명은 이전 자료의 [교차 엔트로피 측정 방식](/doc/3.-Mnist-AvQJchJDGx0KmHuVYqHUZ) 참고
- ADAM 최적화 알고리즘을 사용하여 교차 엔트로피가 최소가 되는 방향으로 학습하도록 모델을 훈련하였다.
- 드롭아웃 레이어의 확률을 조절하는 추가적인 파라미터 keep_drop을 feed_dict 인자를 통해 전달한다.







## 전체 코드
----------
    from tensorflow.examples.tutorials.mnist import input_data
    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
    import tensorflow as tf
    
    x = tf.placeholder("float", shape=[None, 784])
    y_ = tf.placeholder("float", shape=[None, 10])
    
    x_image = tf.reshape(x, [-1,28,28,1])
    print "x_image="
    print x_image
    
    def weight_variable(shape):
      initial = tf.truncated_normal(shape, stddev=0.1)
      return tf.Variable(initial)
    
    def bias_variable(shape):
      initial = tf.constant(0.1, shape=shape)
      return tf.Variable(initial)
    
    def conv2d(x, W):
      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
    
    def max_pool_2x2(x):
      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    
    W_conv1 = weight_variable([5, 5, 1, 32])
    b_conv1 = bias_variable([32])
    
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
    h_pool1 = max_pool_2x2(h_conv1)
    
    W_conv2 = weight_variable([5, 5, 32, 64])
    b_conv2 = bias_variable([64])
    
    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
    h_pool2 = max_pool_2x2(h_conv2)
    
    W_fc1 = weight_variable([7 * 7 * 64, 1024])
    b_fc1 = bias_variable([1024])
    
    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
    
    keep_prob = tf.placeholder("float")
    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
    
    W_fc2 = weight_variable([1024, 10])
    b_fc2 = bias_variable([10])
    
    y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
    
    cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
    correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
    
    sess = tf.Session()
    
    sess.run(tf.global_variables_initializer())
    
    for i in range(20000):
       batch = mnist.train.next_batch(50)
       if i%10 == 0:
         train_accuracy = sess.run( accuracy, feed_dict={ x:batch[0], y_: batch[1], keep_prob: 1.0})
         print("step %d, training accuracy %g"%(i, train_accuracy))
       sess.run(train_step,feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})
    
    print("test accuracy %g"% sess.run(accuracy, feed_dict={
           x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))



## 결과 확인
----------
![](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520327035353_mnist-cnn1.png)

![](https://d2mxuefqeaa7sj.cloudfront.net/s_CAB5F0EABE9BE5EA40C9B93ECBA24C6DB1CAF0DD64967317F1550BDDB7CC6E96_1520327035343_mnist-cnn2.png)


99.3%의 인식률을 확인할 수 있다.

